name: language classifier
description: Fine-tunes RoBERTa with frozen base and custom FC layers for text classification from CSV

inputs:
  - {name: csv_path, type: String, description: 'Path to CSV file containing text and labels'}
  - {name: text_column, type: String, description: 'Name of column containing text data', default: 'text'}
  - {name: label_column, type: String, description: 'Name of column containing labels', default: 'label'}
  - {name: test_size, type: Float, description: 'Proportion of data for validation (0.0-1.0)', default: 0.2}
  - {name: max_sequence_length, type: Integer, description: 'Maximum token length for sequences', default: 128}
  - {name: hidden_layer_1, type: Integer, description: 'Neurons in first FC layer', default: 256}
  - {name: hidden_layer_2, type: Integer, description: 'Neurons in second FC layer', default: 128}
  - {name: dropout, type: Float, description: 'Dropout rate for regularization', default: 0.3}
  - {name: batch_size, type: Integer, description: 'Batch size for training', default: 16}
  - {name: learning_rate, type: Float, description: 'Learning rate for optimizer', default: 0.00002}
  - {name: num_epochs, type: Integer, description: 'Number of training epochs', default: 3}
  - {name: pretrained_model, type: String, description: 'HuggingFace RoBERTa model name', default: 'roberta-base'}

outputs:
  - {name: trained_model, type: Model, description: 'Trained RoBERTa classifier model'}
  - {name: label_encoder, type: Data, description: 'Label encoder for inference'}
  - {name: training_metrics, type: Data, description: 'Training and validation metrics'}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v28
    command:
      - sh
      - -c
      - |
        

    args:
      - --csv_path
      - {inputValue: csv_path}
      - --text_column
      - {inputValue: text_column}
      - --label_column
      - {inputValue: label_column}
      - --test_size
      - {inputValue: test_size}
      - --max_sequence_length
      - {inputValue: max_sequence_length}
      - --hidden_layer_1
      - {inputValue: hidden_layer_1}
      - --hidden_layer_2
      - {inputValue: hidden_layer_2}
      - --dropout
      - {inputValue: dropout}
      - --batch_size
      - {inputValue: batch_size}
      - --learning_rate
      - {inputValue: learning_rate}
      - --num_epochs
      - {inputValue: num_epochs}
      - --pretrained_model
      - {inputValue: pretrained_model}
      - --trained_model
      - {outputPath: trained_model}
      - --label_encoder
      - {outputPath: label_encoder}
      - --training_metrics
      - {outputPath: training_metrics}
